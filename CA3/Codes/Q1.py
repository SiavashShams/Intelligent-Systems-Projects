# -*- coding: utf-8 -*-
"""Copy of cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CGVC86TsvvNscMm0j9eRwM0l_a8AcTvD

# **PART A**
"""

import tensorflow as tf
from keras import layers, models
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import cifar10
from tensorflow.keras.optimizers import SGD

# load data
(train_data, train_label), (test_data, test_label) = cifar10.load_data()
samples = [29, 32, 24, 21, 28, 27, 25, 37, 62, 67]
# plot image of each class
plt.figure(0)
for i in range(5):
    for j in range(2):
        plt.subplot2grid((5, 2), (i, j))
        plt.imshow(train_data[samples[2 * i + j]])
plt.show()

# normalize data
train_data = train_data / 255.0
test_data = test_data / 255.0

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

"""# **PART B**"""

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('2 hidden layers')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('3 hidden layers')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(256, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('4 hidden layers')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

"""# **PART C**"""

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='tanh'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('ReLU activation')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

"""# **PART D**"""

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (2, 2), activation='tanh', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='tanh'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
model.compile(optimizer="adam",
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Tanh activation & ADAM')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
model.compile(optimizer="adam",
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=10,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('ReLU activation & ADAM')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

"""# **PART E**"""

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.1))
model.add(layers.Conv2D(64, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.1))
model.add(layers.Conv2D(128, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.1))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.1))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer="adam",
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=20,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('10% Dropout')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(64, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(128, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.2))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.2))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
model.compile(optimizer="adam",
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=20,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('20% Dropout')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)

# define our model
model = models.Sequential()
model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3),padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.15))
model.add(layers.Conv2D(64, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.15))
model.add(layers.Conv2D(128, (2, 2), activation='relu',padding="same",strides=(1,1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Dropout(0.15))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.15))
model.add(layers.Dense(10,activation='softmax'))
model.summary()

# training the model
model.compile(optimizer="adam",
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
fit_history = model.fit(train_data, train_label, epochs=20,
                    validation_data=(test_data, test_label), batch_size=64)

plt.plot(fit_history.history['accuracy'], label='training accuracy')
plt.plot(fit_history.history['val_accuracy'], label='validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('15% Dropout')
plt.ylim([0.4, 1])
plt.legend(loc='upper left')
plt.show()
# calculate loss and accuracy on test data and print it
test_loss, test_acc = model.evaluate(test_data, test_label, verbose=2)
train_loss, train_acc = model.evaluate(train_data,  train_label, verbose=2)
print("accuracy on test data:",test_acc)
print("loss on test data:",test_loss)
print("accuracy on train data:",train_acc)
print("loss on train data:",train_loss)